# Exam DP-100: Analyzing Data with Power BI

[Study guide](https://learn.microsoft.com/en-us/credentials/certifications/resources/study-guides/dp-100)

[Course](https://learn.microsoft.com/en-us/training/courses/dp-100t01)


## Audience profile
You should have subject matter expertise in:
- applying data science and ML to implement and run ML workloads on Azure. 
- knowledge of optimizing language models for AI applications using Azure AI.

Your responsibilities for this role include:

- Designing and creating a working environment for data science workloads.
- Exploring data.
- Training ML models.
- Implementing pipelines.
- Running jobs to prepare for production.
- Managing, deploying, and monitoring scalable ML solutions.
- Using language models for building AI applications.

As a candidate for this exam, you should have knowledge and experience in data science by using:
- Azure ML
- MLflow
- Azure AI services, including Azure AI Search
- Azure AI Foundry

## Skills
- Design and prepare a ML solution 20%
- Explore data and run experiments 20%
- Train and deploy models 30%
- Optimize language models for AI applications 30%

### Design and prepare a ML solution

#### Design a ML solution
- Identify the structure and format for datasets
- Determine the compute specifications for ML workload
- Select the development approach to train a model

#### Create and manage resources in an Azure ML workspace
- Create and manage a workspace
- Create and manage datastores
- Create and manage compute targets
- Set up Git integration for source control

#### Create and manage assets in an Azure ML workspace
- Create and manage data assets
- Create and manage environments
- Share assets across workspaces by using registries

### Explore data, and run experiments

#### Use automated ML to explore optimal models
- Use automated ML for tabular data
- Use automated ML for computer vision
- Use automated ML for natural language processing
- Select and understand training options, including preprocessing and algorithms
- Evaluate an automated ML run, including responsible AI guidelines

#### Use notebooks for custom model training
- Use the terminal to configure a compute instance
- Access and wrangle data in notebooks
- Wrangle data interactively with attached Synapse Spark pools and serverless Spark compute
- Retrieve features from a feature store to train a model
- Track model training by using MLflow
- Evaluate a model, including responsible AI guidelines

#### Automate hyperparameter tuning
- Select a sampling method
- Define the search space
- Define the primary metric
- Define early termination options

### Train and deploy models

#### Run model training scripts
- Consume data in a job
- Configure compute for a job run
- Configure an environment for a job run
- Track model training with MLflow in a job run
- Define parameters for a job
- Run a script as a job
- Use logs to troubleshoot job run errors

#### Implement training pipelines
- Create custom components
- Create a pipeline
- Pass data between steps in a pipeline
- Run and schedule a pipeline
- Monitor and troubleshoot pipeline runs

#### Manage models
- Define the signature in the MLmodel file
- Package a feature retrieval specification with the model artifact
- Register an MLflow model
- Assess a model by using responsible AI principles

#### Deploy a model
- Configure settings for online deployment
- Deploy a model to an online endpoint
- Test an online deployed service
- Configure compute for a batch deployment
- Deploy a model to a batch endpoint
- Invoke the batch endpoint to start a batch scoring job

### Optimize language models for AI applications

#### Prepare for model optimization
- Select and deploy a language model from the model catalog
- Compare language models using benchmarks
- Test a deployed language model in the playground
- Select an optimization approach

#### Optimize through prompt engineering and prompt flow
- Test prompts with manual evaluation
- Define and track prompt variants
- Create prompt templates
-  chaining logic with the prompt flow SDK
- Use tracing to evaluate your flow

#### Optimize through Retrieval Augmented Generation (RAG)
- Prepare data for RAG, including cleaning, chunking, and embedding
- Configure a vector store
- Configure an Azure AI Search-based index store
- Evaluate your RAG solution

#### Optimize through fine-tuning
- Prepare data for fine-tuning
- Select an appropriate base model
- Run a fine-tuning job
- Evaluate your fine-tuned model